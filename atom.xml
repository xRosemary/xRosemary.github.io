<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xRosemary的个人博客</title>
  <icon>https://www.gravatar.com/avatar/dd7a5c34c75bc70b46646963abcfd04f</icon>
  <subtitle>鼠鼠的救赎</subtitle>
  <link href="https://xrosemary.github.io/atom.xml" rel="self"/>
  
  <link href="https://xrosemary.github.io/"/>
  <updated>2022-09-04T09:27:10.890Z</updated>
  <id>https://xrosemary.github.io/</id>
  
  <author>
    <name>xRosemary</name>
    <email>2862656629@qq.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>在自动驾驶城市中用于360度感知环境的语义相机</title>
    <link href="https://xrosemary.github.io/posts/779.html"/>
    <id>https://xrosemary.github.io/posts/779.html</id>
    <published>2022-09-04T07:59:58.000Z</published>
    <updated>2022-09-04T09:27:10.890Z</updated>
    
    <content type="html"><![CDATA[<h1 id="在自动驾驶城市中用于360度感知环境的语义相机"><a href="#在自动驾驶城市中用于360度感知环境的语义相机" class="headerlink" title="在自动驾驶城市中用于360度感知环境的语义相机"></a>在自动驾驶城市中用于360度感知环境的语义相机</h1><h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>出行的未来是个人交通的自动化，这将带来重大的社会、经济和生态效益。自动化电动交通将缓解大规模城市化和持续交通拥堵带来的挑战,更有效地协调交通中的车辆将通过减少温室气体排放来解决气候变化问题。此外，自动驾驶意味着通过消除人为错误来提高道路安全性。共享汽车将更具吸引力，老年人或残疾人的流动性将得到改善。然而,由于关键技术缺乏成熟，特别是在复杂的城市地区，全车自动化是一个长期的愿景,也是学术界和汽车行业的持续努力。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="1-语义分割-将图像分割成有相同意义的片段-："><a href="#1-语义分割-将图像分割成有相同意义的片段-：" class="headerlink" title="1. 语义分割(将图像分割成有相同意义的片段)："></a>1. 语义分割(将图像分割成有相同意义的片段)：</h3><p>道路中分割出的片段：<strong>车辆、行人、骑自行车的人</strong></p><p>评价标准：</p><pre><code>1. 如何捕获上下文线索2. 如何维护更精细尺度的细节，例如形状和边界3. 更高的输出分辨率</code></pre><h4 id="常用方法：全卷积网络（FCN）"><a href="#常用方法：全卷积网络（FCN）" class="headerlink" title="常用方法：全卷积网络（FCN）"></a>常用方法：全卷积网络（FCN）</h4><p>该方法在公共基准测试上取得了最先进的成果。</p><pre><code>特点：来自CNN的全连接层被卷积层取代</code></pre><p>他人的工作：</p><pre><code>L.-C. Chen，Y. Zhu等人提出的：DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs,L.-C. Chen, Y. Zhu等人提出的：Encoder- decoder with atrous separable convolution for semantic image segmen- tation</code></pre><p>这两种方法通过在最后的残缺块中采用扩张卷积来扩大分类CNN的感知视野，同时提供了更高的输出分辨率。其中第一种方法具有很高的内存占用，因为它在输出分辨率上提高了8倍。</p><p>可变形金字塔网络（PSPNet）通过采用并行池操作和融合不同尺度的特征来捕获全局图像信息。</p><h4 id="另一种流行的CNN架构：编码器-译码器"><a href="#另一种流行的CNN架构：编码器-译码器" class="headerlink" title="另一种流行的CNN架构：编码器-译码器"></a>另一种流行的CNN架构：编码器-译码器</h4><p>B. Shahian Jahromi, T. Tulabandhula等人的论文中提出了一种用于自由空间分割的编码器-译码器网络，该网络在自动化驾驶汽车的实时多传感器感知框架的背景下处理RGBD数据。<br>与针对每个任务单独训练的网络相比，多任务设置中的端到端训练可以提高准确性，并产生了一种更好地泛化的解决方案。</p><p>自动驾驶需要高性能的语义分割算法。上述方法中，编码器-译码器架构实现了准确性和延迟之间的最佳折衷。因此，本文采用了高效的ERNet网络对鱼眼图像进行语义分割，以降低计算成本、提高高质量的分割。</p><h3 id="2-实例分割（预测每个对象的语义掩码和实例标识符，以便我们区分属于同一类别的对象）"><a href="#2-实例分割（预测每个对象的语义掩码和实例标识符，以便我们区分属于同一类别的对象）" class="headerlink" title="2. 实例分割（预测每个对象的语义掩码和实例标识符，以便我们区分属于同一类别的对象）"></a>2. 实例分割（预测每个对象的语义掩码和实例标识符，以便我们区分属于同一类别的对象）</h3><p>该方法通常使用两种方法：候选区域的分割、没有候选区域的实例的分割。</p><p>基于候选区域的分割方案在实例分割方面取得了更好的结果，而单阶段方法可以实现快速推理，并且适用于自动驾驶领域。</p><p>本文在图像分割模块使用的是<strong>RetinaMask方法</strong>，因为它具有高精度、低计算成本、更重要的是降低了推理通道的复杂性，这允许使用Nvidia的深度学习推理引擎，进一步加速并简化部署。</p><h3 id="3-全景分割（将密集的像素分类为事物和特征类，并为图像的每个事物像素分配一个实例标识符）"><a href="#3-全景分割（将密集的像素分类为事物和特征类，并为图像的每个事物像素分配一个实例标识符）" class="headerlink" title="3. 全景分割（将密集的像素分类为事物和特征类，并为图像的每个事物像素分配一个实例标识符）"></a>3. 全景分割（将密集的像素分类为事物和特征类，并为图像的每个事物像素分配一个实例标识符）</h3><p>全景分割可以通过同时解决语义分割和实例分割来实现。</p><pre><code>基里洛夫等人提供基线分析法来解决这个问题，并且提出了一种端到端的可训练网络，通过采用语义和实例logits来在网络内部直接学习的全景输出。虽然这种方法能提供准确的结果，但它们的延迟较高，因此不适合在自动驾驶环境中使用。</code></pre><p><strong>本文提出了一种原始的全景分割融合方案，它使用实例类来纠正语义分类，并通过在语义掩码上传播实例标识符来改进实例掩码。</strong><br>该方法执行速度快，还提供了改进和统一的语义和实例分割输出，并且很容易集成到任何图像分割网络上的后处理步骤。</p><h2 id="测试车辆设置"><a href="#测试车辆设置" class="headerlink" title="测试车辆设置"></a>测试车辆设置</h2><p>UP‑Drive 项目的测试车辆5台是全电动大众 e‑Golf。为了保证 360° 3D 多模态环境感知，车辆上安装了三种不同类型的传感器：摄像头、雷达和激光雷达。传感器设置中集成了五个外部同步摄像头，以覆盖车辆的近距和远距环视：一个位于挡风玻璃后面的 60° 视野摄像头和四个鱼眼摄像头。前后鱼眼摄像头水平安装在车标附近，左右摄像头安装在两侧后视镜上并向下倾斜。该系统配备四个185°宽视野摄像头，可在车辆周围提供360°覆盖，相邻摄像头之间有一些重叠。相机的鱼眼系统提供分辨率为 1280×800、JPEG 压缩为 30 帧/秒的彩色图像。<br><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/2.png" alt="图2"><br>相机的鱼眼系统具有广角镜头和等效的短焦距，这决定了要捕获的大部分场景。与窄视场相机相比，图像中物体的表观尺寸更小。因此，鱼眼相机限制了分割算法的检测范围。从我们的实验中，我们获得了仅 25 米的鱼眼图像的稳健行人分割。检测远处的物体很重要，尤其是在高速行驶时。为了克服这个问题，我们在设置中引入了一个窄视场RGB摄像头，安装在挡风玻璃后面。该相机具有 60°水平视野，以30帧/秒的帧速率提供 1928 × 1208 分辨率的图像，并将检测范围扩大了三倍。完整的传感器套件如图</p><h2 id="带有语义相机的2D感知"><a href="#带有语义相机的2D感知" class="headerlink" title="带有语义相机的2D感知"></a>带有语义相机的2D感知</h2><h3 id="图像预处理：图像去畸变和展开"><a href="#图像预处理：图像去畸变和展开" class="headerlink" title="图像预处理：图像去畸变和展开"></a>图像预处理：图像去畸变和展开</h3><p>由于在原始鱼眼图像中，结构和物体会因为广角镜头而高度失真，因此我们需要通过图像去畸变和图像展开来获取更合适的对应场景的图像。<br><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/3.png" alt="图3"><br><em>鱼眼图像展开过程的结果。第一行：鱼眼图像；第二行：鱼眼图像的圆柱投影。从左到右：前视图，右视图，后视图，左视图</em></p><h3 id="深度语义、实例和全景分割"><a href="#深度语义、实例和全景分割" class="headerlink" title="深度语义、实例和全景分割"></a>深度语义、实例和全景分割</h3><p>深度学习帮我们将分类问题扩展到表示学习，并在许多计算机视觉任务中显示出优于基于手工特征的算法的结果。<br>考虑到深度学习的优势和技术的先进，基于深度神经网络的解决方案很适合用于我们的自动驾驶感知软件。</p><ol><li>图像分割数据集<br>由于缺乏公开可用的360°感知数据集，我们采用了我们自己记录和注释的内部的UP-Drive数据集来训练和评估我们提出的在鱼眼图像上进行语义和实例分割的深度神经网络。<br><strong>这个数据集的一些特征:</strong></li></ol><blockquote><p>1）捕捉了各种照明条件</p><blockquote><p>记录来自德国北部的几个城市以及高速公路和乡村道路从早上到下午，考虑了不同的照明情况</p></blockquote><p>2）天气多样性</p><blockquote><p>时间跨度是在包括了春季夏季和秋季的几个月时间，因此在晴天、多云以及大雨等天气都有记录，甚至包括了镜头炫光、以及雨滴造成的镜头畸变</p></blockquote><p>3）图像覆盖车辆前后左右的周围视野</p><blockquote><p>包含了前视图像5111张、左视图像4684张、右视图像4800张、后视图像4967张</p></blockquote></blockquote><ol><li>语义分割<br>通过实现一个 <strong>全卷积神经网络（FCN）</strong> 用于四个语言图像的语义分割。<br><strong>介绍：</strong><br>考虑到现在先进的语义架构要么非常深要么非常宽，或者以更高的的内存使用和更长的时间为代价使用复杂的层，而在车辆的自动驾驶感知系统又必须使用低功耗硬件设备来实时运行。 <strong>因此我们选择采用了一个在准确性和效率之间取得良好平衡的高效网络ERFNet</strong><br><strong>ERFNet：</strong></li></ol><blockquote><p>该网络具有编码器‑解码器架构，其中编码器提取不同尺度的图像特征，解码器将特征组合成更高分辨率的表示。 ERFNet 的构建块是分解残差层。该层表示一维非瓶颈残差模块，它将二维内核分解为一维内核的线性组合。在这个设计中，每个 3×3 的卷积都被转换为 3×1 和 1×3 的卷积。当使用内核大小为 3 时，参数数量减少了 33%。同时，网络的内存效率更高、速度更快，同时容量增加，从而导致类似于更复杂模型的高精度分割。特征提取器通过堆叠具有扩张卷积的剩余 1D 非瓶颈块以三个尺度对特征进行编码：原始输入分辨率的 1/2、1/4、1/8。为了保留详细信息和小对象，高输出分辨率很重要。卷积层中的膨胀已被证明是一种捕获多尺度上下文的有效机制，这对于正确分类至关重要。轻量级解码器由一维非瓶颈块组成，并从编码器的最后一层恢复空间和语义信息</p><p><strong>实现：</strong><br>我们在具有四个Tesla V100 GPU的系统上用Pytorch框架实现我们的模型。该网络经过150个epoch的训练，每个GPU的批量大小为12个图像，多项式学习率从0.0025开始衰减。另外，交叉熵损失函数用过Adam优化器来优化。我们将图像裁剪为1280*640，并应用随机水平翻转和随机左右平移。这个网络使用Cityscapes数据集上的预训练权重进行初始化。</p></blockquote><ol><li>实例分割<br>我们的深度实例分割网络既要准确高效又要允许使用TenseorRT等深度学习推理引擎进行优化和部署。<br><strong>为了保持整个感知系统的处理时间较低</strong>，又车辆前部的区域包含了最重要的关于安全航行所需的环境信息，所以我们只对前鱼眼图像和窄视场图像进行实例分割<br><strong>我们用于实例分割的最终解决方案采用 RetinaMask</strong></li></ol><blockquote><p>它使用 Mask R‑CNN 类型的实例掩码预测头扩展了最先进的单次目标检测器 RetinaNet 。对于特征提取主干，我们使用带有 5 级特征金字塔网络 (FPN) 的 ResNet‑50 。 FPN 通过编码从 1/4 到 1/64 的多分辨率表示来实现多尺度对象检测。 FPN 遵循原始实现 ，具有 256 个特征图和 5 个锚定尺度。具有四个卷积层的边界框回归和分类头附加到金字塔的每个级别。边界框预测被聚合、过滤并分发到 FPN 中的层。接下来，ROIAlign 操作从每个预测的边界框中采样相同数量的特征（14 × 14），最终由具有四个卷积层和一个转置卷积的掩码预测头处理。最后，[1 × 1] 卷积生成大小为 28 × 28 的最终类别掩码。</p><p>我们在来自 UP‑Drive 数据集的鱼眼和窄视野图像上训练两个实例分割网络。该网络在 Microsoft COCO 数据集和 Cityscapes 数据集上进行了预训练。我们将批量大小设置为 16 个图像，并以 0.01 的基本学习率训练 30k次迭代，在 20k 次迭代时减少 10 。损失函数的优化是使用随机梯度下降 (SGD) 完成的。鱼眼图像被裁剪为 1280 × 640，然后在训练期间使用图像的较短边缘进行缩放</p></blockquote><ol><li>全景分割<br><strong>在全景分割之前，我们发现：</strong></li></ol><blockquote><p>实例分割掩码由于其低分辨率（28*28）而更加原始，并且可以观察到对象边界处的错误，尤其是在对象比较大的情况下，而语义分割提供了事物之间的良好分割和填充像素，但是会混淆同一类别的一些东西。</p><p>因此我们考虑通过融合语义分割和实例分割输出来作为全景分割的方案，这有效解决了语义类之间的实例级重叠和冲突。<br>融合过程如图所示：<br><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/6.png" alt></p></blockquote><ol><li>网络集成和部署<br>最终，我们将分割网络、两个实例分割网络（一个用于鱼眼和一个用于窄 HFV 图像）和全景分割融合算法，如图所示集成到我们在ADTF 中运行的感知软件中<br><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/7.png" alt></li></ol><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>在本论文中，我们提供了 UP‑Drive 数据集上的 2D 语义、实例和全景分割的实验结果。</p><h3 id="实验指标："><a href="#实验指标：" class="headerlink" title="实验指标："></a>实验指标：</h3><pre><code>1. 评估指标：我们使⽤标准mIoU（平均交集⽐联合）指标评估语义分割。2. 执行时间：在批量大小为 1 的 NVIDIA GTX 1080 GPU 上测量。</code></pre><p>评估⻥眼图像的语义分割⽹络，对应于前、左、后、右视图：<br><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/table1.png" alt></p><h3 id="图像分割结果："><a href="#图像分割结果：" class="headerlink" title="图像分割结果："></a>图像分割结果：</h3><p>⻋辆的前部区域被两个摄像头覆盖：</p><pre><code>⼀个窄的 60°⽔平视野摄像头，可在增加深度时提供实例分割；⼀个较宽的 160°⽔平视野摄像头，可提供实例，近程的语义和全景分割。</code></pre><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/2022-05-22-16-00-03.png" alt></p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/2022-05-22-16-05-17.png" alt></p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/2022-05-22-16-09-40.png" alt></p><p>与其他⽅法相⽐，我们的解决⽅案最快，为 68 ms，并且与使⽤更⾼分辨率图像的⽹络实现了可⽐的语义分割 mIoU。然⽽，我们观察到我们的实例分割结果不太准确，因为在下采样图像中检测和分割⼩物体更加困难。从实际的⻆度来看，考虑到施加的约束，我们在速度和准确性之间取得了良好的平衡，以低得多的计算成本获得了具有竞争力的结果。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/2022-05-22-17-14-38.png" alt><br>宽视场和窄视场实例分割的比较。行人在 3D 顶视图图像中标有绿色框，并且宽视场和窄视野图像中的红色边界框。在第一列中，我们提供检测到的3D点云的鸟瞰图对象。最佳彩色和变焦效果。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从多个角度构建全自动车辆原型十分具有挑战性，其中包括：选择最合适的传感器套件、开发在现实世界场景中提供准确结果的快速且稳健的算法、创建用于训练深 度学习算法的质量和完整数据集，以及算法的集成和车辆上的部署。<br>我们的语义摄像机设置可感知车辆周围的 360°。我们的第一个解决方案仅使用安装在所有四个方向上的鱼眼相机。然而，分割和检测范围仅限于车辆周围的近距离。在行人的情况下，分割在 25 米范围内是稳健的，仅适用于非常低速的驾驶和停车操作。对于左视图、右视图和后视图，即使在高速行驶 的情况下，近距离检测也为机动预测和决策提供了足够的信息。然而，远距离 的检测和分割是必要的，尤其是在前视图上。在我们的最终解决方案中，我们 得出结论，鱼眼摄像头和用于前视的窄视场摄像头对于覆盖近距和远距范围都是必要的。此外，另一个重要方面是可以通过处理更高分辨率的图像来增加检测范围。<br>在 UP‑Drive 项目中，我们成功开发了一种能够在城市区域安全导航的自动驾驶汽车。我们为基于鱼眼和窄视场语义相机的环境感知提供了一个模块 化的基于深度学习的解决方案，具有语义、实例和全景分割功能。在本文中，我 们介绍了我们在开发语义环境感知系统时遇到的挑战，因为对准确性、鲁棒性和实时性能的要求很高。我们研究了多种解决方案，激发了我们最终的设计选择，展示了有关分割模块与软件集成的详细信息，最后我们讨论了项目4年过程中的经验教训。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;在自动驾驶城市中用于360度感知环境的语义相机&quot;&gt;&lt;a href=&quot;#在自动驾驶城市中用于360度感知环境的语义相机&quot; class=&quot;headerlink&quot; title=&quot;在自动驾驶城市中用于360度感知环境的语义相机&quot;&gt;&lt;/a&gt;在自动驾驶城市中用于360度感知环</summary>
      
    
    
    
    <category term="Article" scheme="https://xrosemary.github.io/categories/Article/"/>
    
    
    <category term="物联网" scheme="https://xrosemary.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>Bilibili用户社交网络分析</title>
    <link href="https://xrosemary.github.io/posts/f52e.html"/>
    <id>https://xrosemary.github.io/posts/f52e.html</id>
    <published>2022-09-04T07:49:18.000Z</published>
    <updated>2022-09-04T10:30:04.492Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Bilibili用户社交网络分析"><a href="#Bilibili用户社交网络分析" class="headerlink" title="Bilibili用户社交网络分析"></a>Bilibili用户社交网络分析</h1><center><div style="height:2mm;"></div><div style="font-family:华文楷体;font-size:14pt;">xRosemary</div></center><center><span style="font-family:华文楷体;font-size:9pt;line-height:9mm">https://github.com/xRosemary</span></center><div><div style="width:52px;float:left; font-family:方正公文黑体;">摘　要：</div> <div style="overflow:hidden; font-family:华文楷体;">在信息化时代背景下，社交网络分析在各大社交平台中得到广泛关注。本文试图通过爬取哔哩哔哩网页端的数据，并对其进行社交网络分析，包括网络可视化，网络度的分析以及用户影响力发掘等，从而得到一些分析结论，使读者能够对哔哩哔哩平台的社交网络有一个较为全面的了解。</div></div><div><div style="width:52px;float:left; font-family:方正公文黑体;">关键词：</div> <div style="overflow:hidden; font-family:华文楷体;">社交网络；爬取；哔哩哔哩；可视化；用户影响力；</div></div><center><div style="height:2mm;"></div><div style="font-size:14pt;">xRosemary</div></center><center><span style="font-size:9pt;line-height:9mm"><i>https://github.com/xRosemary</i></span></center><div><div style="width:82px;float:left;line-height:16pt"><b>Abstract: </b></div> <div style="overflow:hidden;line-height:16pt">In the information age, social network analysis has been widely concerned in various social platforms.  This paper attempts to crawl the data of Bilibili's webpage and analyze its social network, including network visualization, network degree analysis and user influence excavation, so as to get some analysis conclusions, so that readers can have a more comprehensive understanding of the social network of Bilibili platform.</div></div><div><div style="width:82px;float:left;line-height:16pt"><b>Key Words: </b></div> <div style="overflow:hidden;line-height:16pt">Social network; Crawl; BiliBili; Visualization; User influence;</div></div><center><strong></strong></center><h2 id="数据集的获取"><a href="#数据集的获取" class="headerlink" title="数据集的获取"></a>数据集的获取</h2><p>　　本次实践的数据集是通过爬取bilibili网页端的数据获得，其数据在网页端的存储格式如图 1 所示。本节下面会详细介绍如何实现数据的爬取。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/image-20220518153117813.png" alt="image-20220518153117813"></p><center><strong>图 1  网页数据的格式</strong></center><h3 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h3><p>​    在了解数据的具体结构后，本人据此设计了数据库的存储格式。该数据库的ER图如图 2 所示。User_fans表中主要包括三个字段，主键ID，和两个外键mid，fanID。其中mid代表当前用户的ID，fanID代表该用户粉丝的ID。UserData表主要用来存储用户的详情信息，包括姓名、性别、等级、关注者数量以及粉丝数量。User_fans与UserData之间存在着关联关系，也就是说每一个用户都有他的详情信息。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/image-20220524222713471.png" alt="image-20220524222713471"></p><center><strong>图 2  数据库ER图</strong></center><h3 id="爬虫的编写"><a href="#爬虫的编写" class="headerlink" title="爬虫的编写"></a>爬虫的编写</h3><p>​    本文的爬虫功能是基于 python 3.9 实现的，调用了外部库 requests 来获取网络请求，以及 json 库来解析 json 数据。爬取数据的逻辑是一个双向层次遍历，其结构如图 3 所示。由于事先我们无法获得所有用户的ID，所以只能以一个用户作为切入点，遍历其粉丝列表和关注列表，并以此为基础，获取更多用户的信息。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/image-20220524224158695.png" alt="image-20220524224158695"></p><center><strong>图 3  遍历的结构</strong></center><h2 id="获取数据后的初步分析"><a href="#获取数据后的初步分析" class="headerlink" title="获取数据后的初步分析"></a>获取数据后的初步分析</h2><p>​    本次实验中共爬取了 8801 条数据，在做网络分析前作者对其进行了初步的分析，包括性别分布、粉丝数量统计、关注者数量统计以及用户等级统计等。分析可得，性别保密的用户占大多数，其次是男性、女性；用户等级都是最高等级6级；从整体上来看每个用户关注者数量和粉丝数量都较高，但标准差较大。详细结果如图 4-7 所示。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/%E6%80%A7%E5%88%AB%E6%AF%94%E7%8E%87.png" alt="性别比率" style="zoom:80%;"></p><center><strong>图 4  性别比率</strong></center><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/follower.png" alt="follower" style="zoom:80%;"></p><center><strong>图 5  粉丝数散点图</strong></center><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/following.png" alt="following" style="zoom:80%;"></p><center><strong>图 6  关注者数散点图</strong></center><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/level.png" alt="level" style="zoom:80%;"></p><center><strong>图 7  用户等级分布</strong></center><h2 id="网络结构分析"><a href="#网络结构分析" class="headerlink" title="网络结构分析"></a>网络结构分析</h2><h3 id="网络可视化"><a href="#网络可视化" class="headerlink" title="网络可视化"></a>网络可视化</h3><p>​    网络可视化主要基于包 networkx [1] 和 matplotlib 实现。这里使用了有向图来表达关注与被关注关系，每个节点的出度代表被关注关系，入度代表关注关系。为了方便观看，作者将粉丝数量大于150万的核心用户提取出来进行分析，并将用户的ID转化为用户名，最后根据每个节点的度数对节点的大小进行了缩放处理。最终结果如图 8-9 所示。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/%E5%8F%AF%E8%A7%86%E5%8C%96.png" alt="可视化"></p><center><strong>图 8  网络可视化</strong></center><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/%E5%B1%80%E9%83%A8%E5%9B%BE.png" alt="局部图" style="zoom:80%;"></p><center><strong>图 9  网络局部放大图</strong></center><h3 id="网络度分布与聚类系数"><a href="#网络度分布与聚类系数" class="headerlink" title="网络度分布与聚类系数"></a>网络度分布与聚类系数</h3><p>​    度分布是指网络中度为k的节点的出现概率，而聚类系数表示一个图中节点聚集程度的系数。本文通过 networkx 包中自带的 degree_histogram 方法和 degree_centrality 方法对这两个指标进行统计。其代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络度分布</span></span><br><span class="line">degree=nx.degree_histogram(G)</span><br><span class="line">x=<span class="built_in">range</span>(<span class="built_in">len</span>(degree))</span><br><span class="line">y=[z/<span class="built_in">float</span>(<span class="built_in">sum</span>(degree))<span class="keyword">for</span> z <span class="keyword">in</span> degree]  <span class="comment"># 将频次转化为频率</span></span><br><span class="line">plt.title(<span class="string">&#x27;网络度分布&#x27;</span>)</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类系数</span></span><br><span class="line">centrality = nx.degree_centrality(G)</span><br><span class="line">x=<span class="built_in">range</span>(<span class="built_in">len</span>(centrality))</span><br><span class="line">y = centrality.values()</span><br><span class="line">plt.title(<span class="string">&#x27;聚类系数&#x27;</span>)</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>​    代码运行的结果如图 10-11 所示。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/%E5%BA%A6%E5%88%86%E5%B8%83.png" alt="度分布"></p><center><strong>图 10  网络度分布</strong></center><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/%E8%81%9A%E7%B1%BB%E7%B3%BB%E6%95%B0.png" alt="聚类系数"></p><center><strong>图 11  网络聚类系数</strong></center><pre><code> 从统计结果中可以看出网络的度主要分布在 1-6 附近，但其中的一个节点的度数达到了70以上。从整体上来看满足星型网络的分布情况，即网络通过中心节点将许多点连接而组成。从聚类系数上来看也是，一个节点的聚类系数远远高于其他所有节点，这也验证了前面所述的观点。</code></pre><h3 id="网络其他指标"><a href="#网络其他指标" class="headerlink" title="网络其他指标"></a>网络其他指标</h3><h4 id="网络的密度"><a href="#网络的密度" class="headerlink" title="网络的密度"></a>网络的密度</h4><p>​    网络密度是网络中实际存在的边数与可容纳的边数上限的比值。本文通过 networkx 中的 density 方法实现。其代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络的密度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;图的密度:&#x27;</span>, nx.density(G))</span><br></pre></td></tr></table></figure><h4 id="网络直径"><a href="#网络直径" class="headerlink" title="网络直径"></a>网络直径</h4><p>​    网络直径是指网络中任意两节点间距离的最大值。由于本实验中生成的是有向图，可能存在非连通网络，因此作者现将网络分割成数个连通子网络，然后再进行统计。其代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络直径</span></span><br><span class="line">G_child=<span class="built_in">list</span>(G.subgraph(c) <span class="keyword">for</span> c <span class="keyword">in</span> nx.connected_components(G))</span><br><span class="line">cnt = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> g <span class="keyword">in</span> G_child:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;连通子网络%d的直径:&#x27;</span> % cnt, nx.diameter(g))</span><br><span class="line">    cnt = cnt+<span class="number">1</span></span><br></pre></td></tr></table></figure><p>​    上述代码的运行结果如图 12 所示。</p><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/image-20220524235109574.png" alt="image-20220524235109574"></p><center><strong>图 12  网络其他指标</strong></center><h2 id="用户影响力发掘"><a href="#用户影响力发掘" class="headerlink" title="用户影响力发掘"></a>用户影响力发掘</h2><p>​    在对本实验中的实证网络进行一系列分析后，作者还对本次爬取到的用户的影响力进行了分析，分别计算出了用户权威性最高的前十位用户，以及用户枢纽性最高的前十位用户。这里作者采用了两种方法进行计算，分别是 PageRank 和 HITS 方法 [2]。其主要代码如下所示，运行结果如图 13 所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PageRank</span></span><br><span class="line">pr = nx.pagerank(G)</span><br><span class="line">prsorted = <span class="built_in">sorted</span>(pr.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;基于pagerank算法的用户影响力前10名\n&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> prsorted[:<span class="number">10</span>]:</span><br><span class="line">    <span class="built_in">print</span>(p[<span class="number">0</span>], p[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------------------------------------\n&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># HITS</span></span><br><span class="line">hub, auth = nx.hits(G)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;基于HITS(hub)算法的用户影响力前10名\n&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">sorted</span>(hub.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">10</span>]:</span><br><span class="line"><span class="built_in">print</span>(h[<span class="number">0</span>], h[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------------------------------------\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;基于HITS(auth)算法的用户影响力前10名\n&#x27;</span>)    </span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">sorted</span>(auth.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">10</span>]:     </span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>], a[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/xRosemary/test/main/img/%E7%94%A8%E6%88%B7%E5%BD%B1%E5%93%8D%E5%8A%9B.png" alt="用户影响力" style="zoom:80%;"></p><center><strong>图 13  用户影响力榜单</strong></center><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>​    本文爬取了Bilibili网页端的用户信息，并对该实证网络进行了一系列分析，主要讨论了用户信息分布、网络的结构以及用户的影响力信息。从分析结果可看出该网站用户群体中有一位处于主导地位。由于设备受限，本文只爬取了接近9000条数据，并只筛选出粉丝数大于150万的核心用户进行分析，结果可能与真实分布情况存在一些偏差。不过，该结果也能反映出一些有意义的信息。希望读者通过观看本文，能对Bilibili的用户分布情况有进一步的了解。</p><p><strong>参考文献:</strong> </p><p>［1］  司六米希.【复杂网络】实证网络可视化及其分析 - 含度分布，聚类系数，网络直径，度关联性，权重分析 (性质解析及代码)【python+networkx】[CP].CSDN, [2022-05-20]. <a href="https://blog.csdn.net/weixin_50927106/article/details/123921734">https://blog.csdn.net/weixin_50927106/article/details/123921734</a></p><p>［2］  nana-li.PageRank算法和HITS算法 [CP].CSDN, [2018-07-27]. <a href="https://blog.csdn.net/quiet_girl/article/details/81227904">https://blog.csdn.net/quiet_girl/article/details/81227904</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Bilibili用户社交网络分析&quot;&gt;&lt;a href=&quot;#Bilibili用户社交网络分析&quot; class=&quot;headerlink&quot; title=&quot;Bilibili用户社交网络分析&quot;&gt;&lt;/a&gt;Bilibili用户社交网络分析&lt;/h1&gt;&lt;center&gt;&lt;div styl</summary>
      
    
    
    
    <category term="Python" scheme="https://xrosemary.github.io/categories/Python/"/>
    
    
    <category term="复杂网络分析" scheme="https://xrosemary.github.io/tags/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://xrosemary.github.io/posts/3eeb.html"/>
    <id>https://xrosemary.github.io/posts/3eeb.html</id>
    <published>2022-09-04T01:55:29.266Z</published>
    <updated>2022-09-04T06:30:24.257Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
